{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import math\n",
    "\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "import allensdk.core.json_utilities as ju\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "from mcmodels.core import VoxelModelCache\n",
    "#from mcmodels.core.utils import \n",
    "from mcmodels.core.connectivity_data import get_connectivity_data\n",
    "#from mcmodels.models.crossvalidation import get_nwloocv_predictions_multimodel_merge_dists\n",
    "from mcmodels.utils import nonzero_unique\n",
    "from mcmodels.models.crossvalidation import get_best_hyperparameters,get_loss_best_hyp,get_loss\n",
    "from mcmodels.core.utils import get_structure_id,get_ordered_summary_structures, get_leaves_ontologicalorder, get_indices_2ormore, get_indices, get_indices2,get_eval_indices,screen_index_matrices,screen_index_matrices2,screen_index_matrices3\n",
    "from mcmodels.regressors import NadarayaWatson\n",
    "from mcmodels.core.plotting import plot_loss_surface,plot_loss_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_cre_distances(projections, means_cast, sids, cres):\n",
    "    nsamp = cres.shape[0]\n",
    "    credist = np.empty((nsamp,nsamp))\n",
    "    credist[:] = np.nan\n",
    "    for i in range(nsamp):\n",
    "        #print(i)\n",
    "        meani = means_cast[sids[i]][cres[i]]#means_cast.loc[tuple([cres[i], sids[i]])]\n",
    "        for j in range(nsamp):\n",
    "            meanj = means_cast[sids[j]][cres[j]]\n",
    "            if sids[j] == sids[i]:\n",
    "                credist[i,j]  = np.linalg.norm(meani - meanj)#**2\n",
    "    return(credist)\n",
    "\n",
    "def get_loss_surface_cv_spline(projections, centroids, cres, sids,fraction):\n",
    "    means_cast = get_means(projections, cres, sids)\n",
    "    cre_distances_cv = get_cre_distances_cv(projections, means_cast, sids, cres)\n",
    "    surface = get_surface_from_distances_spline(projections,centroids,cre_distances_cv, fraction)\n",
    "    surface.cre_distances_cv = cre_distances_cv\n",
    "    return(surface)\n",
    "\n",
    "def get_surface_from_distances_spline(projections,centroids,cre_distances, fraction):\n",
    "    \n",
    "    nsamp = centroids.shape[0]\n",
    "    pairs = np.asarray(np.where(~np.isnan(cre_distances))).transpose() #not all cres will have distances, e.g. if not in same leaf\n",
    "    ngp = pairs.shape[0]\n",
    "    \n",
    "    coordinates = np.zeros((ngp,2))\n",
    "    projection_distances = np.zeros((ngp,1))\n",
    "    for i in range(ngp):\n",
    "        coordinates[i,0] = np.linalg.norm(centroids[pairs[i][0]] - centroids[pairs[i][1]])**2\n",
    "        coordinates[i,1] = cre_distances[pairs[i][0]][pairs[i][1]]\n",
    "        projection_distances[i] = np.linalg.norm(projections[pairs[i][0]] - projections[pairs[i][1]])**2\n",
    "    coordinates_normed = coordinates / np.linalg.norm(coordinates, axis = 0)#**2\n",
    "    coordinates_normed[np.where(np.isnan(coordinates_normed))] = 0.\n",
    "    #was n_splines = 10\n",
    "    surface = LinearGAM(s(0, constraints=['monotonic_inc', 'concave'], n_splines=10) + \n",
    "                        s(1, constraints=['monotonic_inc', 'concave'], n_splines=10))\n",
    "\n",
    "    #surface = NadarayaWatson(kernel='rbf',  gamma  = gamma)\n",
    "    randos = random.sample(list(range(ngp)), math.floor(ngp * fraction))\n",
    "    surface.fit(coordinates_normed[randos], projection_distances[randos])\n",
    "    surface.coordinates_normed = coordinates_normed\n",
    "    surface.norms = np.linalg.norm(coordinates, axis = 0)\n",
    "    surface.projection_distances = projection_distances\n",
    "    return(surface)\n",
    "\n",
    "def get_surface_from_distances_nw(projections,centroids,cre_distances, fraction, gamma = 100000):\n",
    "    \n",
    "    nsamp = centroids.shape[0]\n",
    "    pairs = np.asarray(np.where(~np.isnan(cre_distances))).transpose() #not all cres will have distances, e.g. if not in same leaf\n",
    "    ngp = pairs.shape[0]\n",
    "    \n",
    "    coordinates = np.zeros((ngp,2))\n",
    "    projection_distances = np.zeros((ngp,1))\n",
    "    for i in range(ngp):\n",
    "        coordinates[i,0] = np.linalg.norm(centroids[pairs[i][0]] - centroids[pairs[i][1]])**2\n",
    "        coordinates[i,1] = cre_distances[pairs[i][0]][pairs[i][1]]\n",
    "        projection_distances[i] = np.linalg.norm(projections[pairs[i][0]] - projections[pairs[i][1]])**2\n",
    "    coordinates_normed = coordinates / np.linalg.norm(coordinates, axis = 0)#**2\n",
    "    \n",
    "    \n",
    "    \n",
    "    surface = NadarayaWatson(kernel='rbf',  gamma  = gamma)\n",
    "    randos = random.sample(list(range(ngp)), math.floor(ngp * fraction))\n",
    "    #print(coordinates_normed[randos])\n",
    "    surface.fit(coordinates_normed[randos], projection_distances[randos])\n",
    "    surface.coordinates_normed = coordinates_normed\n",
    "    surface.norms = np.linalg.norm(coordinates, axis = 0)\n",
    "    surface.projection_distances = projection_distances\n",
    "    return(surface)\n",
    "\n",
    "def get_means(projections, cres, sids):\n",
    "    cre_means = {}\n",
    "    cre_types = np.unique(cres)\n",
    "    sid_types = np.unique(sids)\n",
    "    for i in range(len(sid_types)):\n",
    "        cre_means[sid_types[i]] = {}\n",
    "        sid_inds = np.where(sids == sid_types[i])[0]\n",
    "        for j in range(len(cre_types)): \n",
    "            cre_inds = np.where(cres == cre_types[j])[0]\n",
    "            cre_means[sid_types[i]][cre_types[j]] = np.mean(projections[np.intersect1d(sid_inds, cre_inds)], axis = 0 )\n",
    "    return(cre_means)\n",
    "\n",
    "def get_cre_distances_cv(proj, means_cast, sids,cres):\n",
    "    nsamp = cres.shape[0]\n",
    "    credist = np.empty((nsamp,nsamp))\n",
    "    credist[:] = np.nan\n",
    "    for i in range(nsamp):\n",
    "        #print(i)\n",
    "        meani = meani = means_cast[sids[i]][cres[i]]\n",
    "        ls = np.where(sids == sids[i])[0]\n",
    "        crs = np.where(cres == cres[i])[0]\n",
    "        ncr = len(np.intersect1d(ls, crs))\n",
    "        \n",
    "        meanloocvi = meani\n",
    "        if ncr > 1:\n",
    "            meanloocvi = (ncr * meani ) / (ncr - 1) -   (1/ ncr)* proj[i] #results[reg[i]][tuple([cs[reg_cre_ind[j],1], cs[reg_cre_ind[k],1]])]\n",
    "        else:\n",
    "            meanloocvi = np.zeros(proj[i].shape[0])\n",
    "            meanloocvi[:] = np.nan\n",
    "            \n",
    "        for j in range(nsamp):\n",
    "            meanj = means_cast[sids[j]][cres[j]]\n",
    "            #require same sid to compute cre distance\n",
    "            if sids[j] == sids[i]:\n",
    "                if cres[i] != cres[j]:\n",
    "                    credist[j,i]  = np.linalg.norm(meanloocvi - meanj)\n",
    "                else: \n",
    "                    credist[j,i] = 0.\n",
    "  \n",
    "    return(credist)\n",
    "\n",
    "def get_embedding_cv(surface, dists, cre_distances_cv):\n",
    "    \n",
    "    ntrain = dists.shape[0]\n",
    "    norms = surface.norms\n",
    "    norms[np.where(norms == 0.)] = 1.\n",
    "    leaf_pairs = np.asarray(np.where(~np.isnan(cre_distances_cv))).transpose()\n",
    "    nlp = leaf_pairs.shape[0]\n",
    "    \n",
    "    losses = np.zeros((ntrain, ntrain))\n",
    "    for i in range(nlp):\n",
    "        d_ij = dists[leaf_pairs[i][0]][leaf_pairs[i][1]] / norms[0]\n",
    "        p_ij = cre_distances_cv[leaf_pairs[i][0]][leaf_pairs[i][1]] / norms[1]\n",
    "        losses[leaf_pairs[i][0]][leaf_pairs[i][1]] = surface.predict(np.asarray([[d_ij, p_ij]]))\n",
    "      \n",
    "    losses[np.where(losses == 0)] = np.nan\n",
    "    \n",
    "    return(losses)\n",
    "\n",
    "\n",
    "from mcmodels.core import Mask\n",
    "\n",
    "\n",
    "def get_embedding(surface, dists, cres = None, cre = None, means = None):\n",
    "    \n",
    "    ntrain = dists.shape[0]\n",
    "    neval = dists.shape[1]\n",
    "    norms = surface.norms\n",
    "    #cnorm = surface.cnorm\n",
    "    \n",
    "    cre_deezy = np.zeros((ntrain))\n",
    "    \n",
    "    for i in range(ntrain):\n",
    "        cre_deezy[i] = np.linalg.norm(means[cres[i]] - means[cre])\n",
    "    \n",
    "    losses = np.zeros((ntrain, neval))\n",
    "    for i in range(ntrain):\n",
    "        for j in range(neval):\n",
    "            d_ij = dists[i,j] / norms[0]\n",
    "            p_i = cre_deezy[i] / norms[1]\n",
    "            losses[i,j] = surface.predict(np.asarray([[d_ij, p_i]]))\n",
    "            \n",
    "    return(losses)\n",
    "\n",
    "\n",
    "\n",
    "def get_nw_predictions(projections, dists, gamma):\n",
    "  \n",
    "     \n",
    "    projections = np.asarray(projections, dtype=np.float32)\n",
    "    neval = dists.shape[1]\n",
    "    #nexp = centroids.shape[0]\n",
    "    predictions = np.zeros((neval, projections.shape[1]))\n",
    "    predictions[:] = np.nan\n",
    "    \n",
    "    #print(model_index_val.shape, eval_index_val.shape)\n",
    "    #weights = np.exp(- dists / gamma)#np.exp(-dists[model_index_val] / gamma) #get_weights(centroids, gamma)\n",
    "    for i in range(neval):\n",
    "        dists_i = dists[:,i] - np.min(dists[:,i])\n",
    "        #dists_i = dists[i,:] - np.min(dists[i,:])\n",
    "        weights_i = np.exp(- dists_i * gamma)\n",
    "        weights_i = np.asarray(weights_i, dtype=np.float32)\n",
    "        weights_i[np.isnan(weights_i)] = 0.\n",
    "        weights_i = weights_i / np.sum(weights_i)\n",
    "        predictions[i] = np.dot(weights_i, projections)\n",
    "        \n",
    "    return(predictions) \n",
    "\n",
    "def get_connectivity_matrices2_nw(connectivity_data, gamma_dict, cres, structures, model_ordering, source_ordering, target_ordering, eval_cres, cre_model = True):\n",
    "    \n",
    "    nsource = len(source_ordering)\n",
    "    #n#target = len(target_ordering)\n",
    "    ncre = len(eval_cres)\n",
    "\n",
    "    ipsi_target_regions = connectivity_data.ipsi_target_regions\n",
    "    contra_target_regions = connectivity_data.contra_target_regions                               \n",
    "    ipsi_indices= np.asarray([])\n",
    "    contra_indices = np.asarray([])\n",
    "    for iy in target_ordering: \n",
    "        ipsi_indices = np.concatenate([ipsi_indices, np.where(ipsi_target_regions==iy)[0]] )\n",
    "        contra_indices = np.concatenate([contra_indices, np.where(contra_target_regions==iy)[0]] )\n",
    "    ipsi_indices = np.asarray(ipsi_indices, dtype = int)   \n",
    "    contra_indices = np.asarray(contra_indices, dtype = int)    \n",
    "    reorder = np.concatenate([ipsi_indices, len(ipsi_indices) + contra_indices])  \n",
    "    ntarget = len(reorder)\n",
    "      \n",
    "    connectivity = np.zeros((ncre, nsource, ntarget))\n",
    "    connectivity[:] = np.nan\n",
    "    #structure_major_dictionary = connectivity_data.structure_major_dictionary\n",
    "    for c in range(ncre):\n",
    "        for i in range(nsource):\n",
    "            print(i,source_ordering[i])\n",
    "            sid = model_ordering[i,0]#structure_major_dictionary[source_ordering[i]]\n",
    "            gamma = gamma_dict[sid]\n",
    "            connectivity[c,i] = get_region_prediction2(cache,\n",
    "                                                      connectivity_data.structure_datas[sid],\n",
    "                                                      exp_structures = structures[sid],\n",
    "                                                      model_region = model_ordering[i,1],\n",
    "                                                      prediction_region= source_ordering[i],\n",
    "                                                      cre = eval_cres[c],\n",
    "                                                      gamma = gamma_dict[sid],\n",
    "                                                      cre_model = cre_model)\n",
    "                                                      \n",
    "    connectivity = connectivity[:,:,reorder]                                                  \n",
    "                                                      \n",
    "    return(connectivity)\n",
    "\n",
    "\n",
    "def get_region_prediction2(cache, structure_data,  exp_structures, model_region, prediction_region, cre, gamma, surface = None, cre_model = False):\n",
    "    \n",
    "    model_experiments = np.where(exp_structures == model_region)[0]\n",
    "    nexp = len(model_experiments)\n",
    "    \n",
    "    cres = structure_data.crelines[model_experiments]\n",
    "    mask = Mask.from_cache(cache,structure_ids=[prediction_region],hemisphere_id=2)\n",
    "\n",
    "      \n",
    "    if surface != None and cre_model == True:\n",
    "        projections = structure_data.reg_proj_norm[model_experiments]\n",
    "        centroids = structure_data.centroids[model_experiments]\n",
    "        means = get_means(projections, cres, np.repeat(model_region,nexp))\n",
    "        #print(means)\n",
    "        print(prediction_region, model_region,means.keys())\n",
    "        #supposed to check if theres a cre in that region\n",
    "        if np.isin(model_region, list(means.keys())):\n",
    "            if np.isin(cre, np.asarray(list(means[model_region].keys()))):\n",
    "                losses = get_embedding(surface, pairwise_distances(centroids, mask.coordinates)**2, cres, cre, means[model_region])\n",
    "                predictions = get_nw_predictions(projections, losses, gamma)\n",
    "                output = np.mean(predictions, axis = 0)\n",
    "            else:\n",
    "                output = np.zeros(projections.shape[1])\n",
    "                output[:] = np.nan\n",
    "        else:\n",
    "            output = np.zeros(projections.shape[1])\n",
    "            output[:] = np.nan           \n",
    "   \n",
    "    if surface == None and cre_model == True:\n",
    "        \n",
    "        \n",
    "        modelcre_experiments = np.where(cres == cre)[0]\n",
    "        if len(modelcre_experiments)>0:\n",
    "            projections = structure_data.reg_proj_norm[model_experiments][modelcre_experiments]\n",
    "            centroids = structure_data.centroids[model_experiments][modelcre_experiments]\n",
    "            #print((pairwise_distances(centroids, mask.coordinates)**2).shape)\n",
    "            predictions = get_nw_predictions(projections, pairwise_distances(centroids, mask.coordinates)**2, gamma)\n",
    "            output = np.mean(predictions, axis = 0)\n",
    "        else:\n",
    "            output = np.zeros(structure_data.reg_proj_norm.shape[1])\n",
    "            output[:] = np.nan  \n",
    "            \n",
    "    if surface == None and cre_model == False:\n",
    "        \n",
    "        if len(model_experiments)>0:\n",
    "            projections = structure_data.reg_proj_norm[model_experiments]\n",
    "            centroids = structure_data.centroids[model_experiments]\n",
    "            predictions = get_nw_predictions(projections, pairwise_distances(centroids, mask.coordinates)**2, gamma)\n",
    "            output = np.mean(predictions, axis = 0)\n",
    "        else:\n",
    "            output = np.zeros(structure_data.reg_proj_norm.shape[1])\n",
    "            output[:] = np.nan  \n",
    "        \n",
    "    return(output)\n",
    "\n",
    "\n",
    "#good one\n",
    "#model_ordering_leafs,model_region_structures are len n exps, which model to use\n",
    "#model_experiments_leaf,model_experiments_structure are inds of \n",
    "def get_connectivity_matrices3(connectivity_data, surfaces, cres, structures_smooth,structures_surface, model_ordering_leafs, model_ordering_surfaces, source_ordering, target_ordering, eval_cres):\n",
    "    \n",
    "    nsource = len(source_ordering)\n",
    "    #n#target = len(target_ordering)\n",
    "    ncre = len(eval_cres)\n",
    "\n",
    "    ipsi_target_regions = connectivity_data.ipsi_target_regions\n",
    "    contra_target_regions = connectivity_data.contra_target_regions                               \n",
    "    ipsi_indices= np.asarray([])\n",
    "    contra_indices = np.asarray([])\n",
    "    for iy in target_ordering: \n",
    "        ipsi_indices = np.concatenate([ipsi_indices, np.where(ipsi_target_regions==iy)[0]] )\n",
    "        contra_indices = np.concatenate([contra_indices, np.where(contra_target_regions==iy)[0]] )\n",
    "    ipsi_indices = np.asarray(ipsi_indices, dtype = int)   \n",
    "    contra_indices = np.asarray(contra_indices, dtype = int)    \n",
    "    reorder = np.concatenate([ipsi_indices, len(ipsi_indices) + contra_indices])  \n",
    "    ntarget = len(reorder)\n",
    "      \n",
    "    connectivity = np.zeros((ncre, nsource, ntarget))\n",
    "    connectivity[:] = np.nan\n",
    "    #structure_major_dictionary = connectivity_data.structure_major_dictionary\n",
    "    for c in range(ncre):\n",
    "        for i in range(nsource):\n",
    "            print(i,source_ordering[i])\n",
    "            sid = model_ordering_leafs[i,0]#structure_major_dictionary[source_ordering[i]]\n",
    "            gamma = surfaces[sid].gamma#gamma_dict[sid]\n",
    "            connectivity[c,i] = get_region_prediction3(cache,\n",
    "                                                      connectivity_data.structure_datas[sid],\n",
    "                                                      #structures_sid = structures[sid],\n",
    "                                                       structures_surface_sid =structures_surface[sid],\n",
    "                                                       structures_smooth_sid= structures_smooth[sid],\n",
    "                                                      model_region_leaf = model_ordering_leafs[i,1],\n",
    "                                                       model_region_surface = model_ordering_surfaces[i,1],\n",
    "                                                      prediction_region= source_ordering[i],\n",
    "                                                      cre = eval_cres[c],\n",
    "                                                      gamma = surfaces[sid].bestgamma,\n",
    "                                                      surface = surfaces[sid],\n",
    "                                                      cre_model = True)\n",
    "                                                      \n",
    "    connectivity = connectivity[:,:,reorder]                                                  \n",
    "                                                      \n",
    "    return(connectivity)\n",
    "\n",
    "def get_region_prediction3(cache, structure_data,  structures_surface_sid,structures_smooth_sid, model_region_surface, model_region_leaf, prediction_region, cre, gamma, surface = None, cre_model = False):\n",
    "    \n",
    "\n",
    "    model_experiments_leaf = np.where(structures_smooth_sid == model_region_leaf)[0]\n",
    "    model_experiments_surface = np.where(structures_surface_sid == model_region_surface)[0]\n",
    "    \n",
    "    nexp_surface = len(model_experiments_surface)\n",
    "    \n",
    "    cres_surface = structure_data.crelines[model_experiments_surface]\n",
    "    mask = Mask.from_cache(cache,structure_ids=[prediction_region],hemisphere_id=2)\n",
    "    if surface != None and cre_model == True:\n",
    "        projections = structure_data.reg_proj_norm[model_experiments_leaf]\n",
    "        projections_surface = structure_data.reg_proj_norm[model_experiments_surface]\n",
    "        centroids = structure_data.centroids[model_experiments_leaf]#model_region_leaf\n",
    "        means = get_means(projections_surface, cres_surface, np.repeat(model_region_surface,nexp_surface))\n",
    "        #supposed to check if theres a cre in that region\n",
    "        #if np.isin(model_region_surface, list(means.keys())):\n",
    "        if centroids.shape[0]>0:\n",
    "            if np.isin(cre, np.asarray(list(means[model_region_surface].keys()))):\n",
    "                losses = get_embedding(surface, pairwise_distances(centroids, mask.coordinates)**2, cres_surface, cre, means[model_region_surface])\n",
    "                predictions = get_nw_predictions(projections, losses, gamma)\n",
    "                output = np.mean(predictions, axis = 0)\n",
    "            else:\n",
    "                output = np.zeros(projections.shape[1])\n",
    "                output[:] = np.nan\n",
    "        else:\n",
    "            output = np.zeros(projections.shape[1])\n",
    "            output[:] = np.nan\n",
    "    if surface == None and cre_model == True:\n",
    "        \n",
    "        \n",
    "        modelcre_experiments = np.where(cres == cre)[0]\n",
    "        if len(modelcre_experiments)>0:\n",
    "            projections = structure_data.reg_proj_norm[model_experiments][modelcre_experiments]\n",
    "            centroids = structure_data.centroids[model_experiments][modelcre_experiments]\n",
    "            #print((pairwise_distances(centroids, mask.coordinates)**2).shape)\n",
    "            predictions = get_nw_predictions(projections, pairwise_distances(centroids, mask.coordinates)**2, gamma)\n",
    "            output = np.mean(predictions, axis = 0)\n",
    "        else:\n",
    "            output = np.zeros(structure_data.reg_proj_norm.shape[1])\n",
    "            output[:] = np.nan  \n",
    "            \n",
    "    if surface == None and cre_model == False:\n",
    "        \n",
    "        if len(model_experiments)>0:\n",
    "            projections = structure_data.reg_proj_norm[model_experiments]\n",
    "            centroids = structure_data.centroids[model_experiments]\n",
    "            predictions = get_nw_predictions(projections, pairwise_distances(centroids, mask.coordinates)**2, gamma)\n",
    "            output = np.mean(predictions, axis = 0)\n",
    "        else:\n",
    "            output = np.zeros(structure_data.reg_proj_norm.shape[1])\n",
    "            output[:] = np.nan  \n",
    "        \n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation/ccf_2017\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "TOP_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "INPUT_JSON = os.path.join(TOP_DIR, 'input_011520.json')\n",
    "EXPERIMENTS_EXCLUDE_JSON = os.path.join(TOP_DIR, 'experiments_exclude.json')\n",
    "FILE_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "OUTPUT_DIR = os.path.join(FILE_DIR, 'output')\n",
    "\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "\n",
    "#its unclear why the hyperparameters are loaded from the output directory\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "major_structures = input_data.get('structures')\n",
    "major_structure_ids = [get_structure_id(cache, s) for s in major_structures]\n",
    "data_info = pd.read_excel('/Users/samsonkoelle/alleninstitute/Whole Brain Cre Image Series_curation only.xlsx', 'all datasets curated_070919pull')\n",
    "data_info.set_index(\"id\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load version 3 list\n",
    "ontological_order = get_ordered_summary_structures(cache,167587189)\n",
    "#due to redundancy in ccfv3, remove 'MDRNv', 'MDRNd' from summary structures (include as leafs of MDRN)\n",
    "ontological_order[277]\n",
    "ontological_order = np.setdiff1d(ontological_order, [1098, 1107])\n",
    "#load version 2 list\n",
    "#ontological_order = get_ordered_summary_structures(cache,687527945)\n",
    "\n",
    "mcc = MouseConnectivityCache(manifest_file = '../connectivity/mouse_connectivity_manifest.json')\n",
    "st = mcc.get_structure_tree()\n",
    "ai_map = st.get_id_acronym_map()\n",
    "ia_map = {value: key for key, value in ai_map.items()}\n",
    "\n",
    "#regionalize voxel model: compare with regional model\n",
    "#regional parameters\n",
    "cre = None\n",
    "eid_set=None\n",
    "high_res=False\n",
    "threshold_injection = False\n",
    "\n",
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load version 3 list\n",
    "ontological_order = get_ordered_summary_structures(cache,167587189)\n",
    "#due to redundancy in ccfv3, remove 'MDRNv', 'MDRNd' from summary structures (include as leafs of MDRN)\n",
    "ontological_order[277]\n",
    "ontological_order = np.setdiff1d(ontological_order, [1098, 1107])\n",
    "#load version 2 list\n",
    "#ontological_order = get_ordered_summary_structures(cache,687527945)\n",
    "\n",
    "mcc = MouseConnectivityCache(manifest_file = '../connectivity/mouse_connectivity_manifest.json')\n",
    "st = mcc.get_structure_tree()\n",
    "ai_map = st.get_id_acronym_map()\n",
    "ia_map = {value: key for key, value in ai_map.items()}\n",
    "\n",
    "#regionalize voxel model: compare with regional model\n",
    "#regional parameters\n",
    "cre = None\n",
    "eid_set=None\n",
    "high_res=False\n",
    "threshold_injection = False\n",
    "\n",
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "703\n",
      "1089\n",
      "1097\n",
      "315\n",
      "313\n",
      "354\n",
      "698\n",
      "771\n",
      "803\n",
      "477\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "connectivity_data = get_connectivity_data(cache, major_structure_ids, experiments_exclude, remove_injection = False, structure_set_id=167587189)\n",
    "\n",
    "connectivity_data.get_injection_hemisphere_ids()\n",
    "connectivity_data.align()\n",
    "connectivity_data.get_centroids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connectivity_data.get_data_matrices(default_structure_ids)\n",
    "connectivity_data.get_crelines(data_info)\n",
    "with open('data/info/leafs.pickle', 'rb') as handle:\n",
    "    leafs = pickle.load(handle)\n",
    "    \n",
    "connectivity_data.ai_map = ai_map\n",
    "connectivity_data.get_summarystructures(data_info)\n",
    "connectivity_data.leafs = leafs\n",
    "\n",
    "# nexp = np.zeros(12)\n",
    "# for i in range(12):\n",
    "#     sid = major_structure_ids[i]\n",
    "#     nexp[i] = len(leafs[sid])\n",
    "# nexp.sum()\n",
    "ontological_order_leaves = get_leaves_ontologicalorder(connectivity_data, ontological_order)\n",
    "#change ontological_order to ontologial_order_leaves for leaf targets\n",
    "\n",
    "#Key isn't affected by which experiment we choose. This allows default masking to be inherited from the AllenSDK.\n",
    "sid0 = list(connectivity_data.structure_datas.keys())[0]\n",
    "eid0 = list(connectivity_data.structure_datas[sid0].experiment_datas.keys())[0]\n",
    "#Identify keys denoting which voxels correspond to which structure in the ipsi and contra targets.\n",
    "contra_targetkey = connectivity_data.structure_datas[sid0].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=1)\n",
    "ipsi_targetkey = connectivity_data.structure_datas[sid0].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=2)\n",
    "ipsi_target_regions, ipsi_target_counts = nonzero_unique(ipsi_targetkey, return_counts=True)\n",
    "contra_target_regions, contra_target_counts = nonzero_unique(contra_targetkey, return_counts=True)\n",
    "\n",
    "target_order = lambda x: np.array(ontological_order)[np.isin(ontological_order, x)]\n",
    "permutation = lambda x: np.argsort(np.argsort(target_order(x)))\n",
    "targ_ids = np.concatenate([ipsi_target_regions[permutation(ipsi_target_regions)],\n",
    "                           contra_target_regions[permutation(contra_target_regions)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connectivity_data.get_regionalized_normalized_data(ontological_order, ipsi_targetkey, contra_targetkey)\n",
    "connectivity_data.get_creleaf_combos()\n",
    "connectivity_data.leaf2_index_matrices = get_indices_2ormore(connectivity_data.leafs)\n",
    "connectivity_data.creleaf2_index_matrices = get_indices_2ormore(connectivity_data.creleaf_combos)\n",
    "\n",
    "frac_learn = np.ones(12)\n",
    "frac_learn[4] = .1\n",
    "#sls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_structures = {}\n",
    "for sid in major_structure_ids:\n",
    "    summary_structures[sid] = connectivity_data.structure_datas[sid].summary_structures\n",
    "connectivity_data.summary_structures = summary_structures#get_indices_2ormore(connectivity_data.leafs)\n",
    "\n",
    "connectivity_data.get_regionalized_normalized_data(ontological_order, ipsi_targetkey, contra_targetkey)\n",
    "connectivity_data.get_creleaf_combos()\n",
    "connectivity_data.leaf2_index_matrices = get_indices_2ormore(connectivity_data.leafs)\n",
    "connectivity_data.creleaf2_index_matrices = get_indices_2ormore(connectivity_data.creleaf_combos)\n",
    "\n",
    "connectivity_data.get_regionalized_normalized_data(ontological_order, ipsi_targetkey, contra_targetkey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 621)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity_data.structure_datas[315].reg_proj_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#connectivity_data.sum2_index_matrices = get_indices_2ormore(connectivity_data.summary_structures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "from pygam import LinearGAM,PoissonGAM, te, s, f\n",
    "for m in range(12):\n",
    "    print(m)\n",
    "    sid = major_structure_ids[m]\n",
    "    connectivity_data.structure_datas[sid].loss_surface_cv_leaf = get_loss_surface_cv_spline(connectivity_data.structure_datas[sid].reg_proj_norm,\n",
    "                                                                                                 connectivity_data.structure_datas[sid].centroids,\n",
    "                                                                                                 connectivity_data.creline[sid],\n",
    "                                                                                                 connectivity_data.leafs[sid],\n",
    "                                                                                                 frac_learn[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(list(connectivity_data.structure_datas.keys()))):\n",
    "    sid = major_structure_ids[m]\n",
    "    print(m)\n",
    "    connectivity_data.structure_datas[sid].smoothed_losses_leaf = get_embedding_cv(surface = connectivity_data.structure_datas[sid].loss_surface_cv_leaf,\n",
    "                                                                              dists = pairwise_distances(connectivity_data.structure_datas[sid].centroids)**2,\n",
    "                                                                              cre_distances_cv = connectivity_data.structure_datas[sid].loss_surface_cv_leaf.cre_distances_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Crossval:\n",
    "    \n",
    "    def __init__(self):\n",
    "        2+2\n",
    "        \n",
    "from mcmodels.models.voxel.crossvalidation import get_nwloocv_predictions_multimodel_merge_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connectivity_data.creleaf2_index_matrices = get_indices_2ormore(connectivity_data.creleaf_combos)\n",
    "connectivity_data.creleaf2_evalindices = get_eval_indices(connectivity_data.creleaf2_index_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = Crossval()\n",
    "\n",
    "#gammas = np.asarray([0.1,.5,1,2,10,20,40,100,1000,10000])\n",
    "gammas = np.asarray([0.0001,0.001,0.01,0.1,1,10,100,1000,10000])\n",
    "#gammas = np.asarray([0.1,.5,1,2,10,20,40])\n",
    "loocvpredictions = {}\n",
    "reg_proj_norm= {}\n",
    "for sid in np.asarray(list(connectivity_data.structure_datas.keys())):\n",
    "    reg_proj_norm[sid ] = connectivity_data.structure_datas[sid].reg_proj_norm\n",
    "    loocvpredictions[sid] = get_nwloocv_predictions_multimodel_merge_dists(connectivity_data.structure_datas[sid].reg_proj_norm, \n",
    "                                                                                       connectivity_data.structure_datas[sid].smoothed_losses_leaf,#np.ones(losses.shape),#(losses - np.nanmin(losses))**2,#**6, \n",
    "                                                                                       #pds,                                       \n",
    "                                                                                       #(sls[sid] - np.nanmin(sls[sid]))**.5,\n",
    "                                                                                       gammas, \n",
    "                                                                                       connectivity_data.leaf2_index_matrices[sid], \n",
    "                                                                                       connectivity_data.leaf2_index_matrices[sid])                                  \n",
    "                                                                                       #screened_eval_indices[sid])                                  \n",
    "                                                                                       #indices_leaf2ormore[sid])\n",
    "            \n",
    "    \n",
    "    \n",
    "a= [list(range(len(gammas)))]\n",
    "keys = np.asarray(list(itertools.product(*a)))\n",
    "\n",
    "cv.loocvpredictions = loocvpredictions\n",
    "\n",
    "cv.losses = get_loss(reg_proj_norm, cv.loocvpredictions,pred_ind = connectivity_data.creleaf2_evalindices, true_ind = connectivity_data.creleaf2_evalindices,keys = keys)\n",
    "cv.bestgamma  = get_best_hyperparameters(cv.losses,keys)\n",
    "cv.meanloss = get_loss_best_hyp(cv.losses, cv.bestgamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03646222, 0.4970684 , 0.09578919, 0.23899943, 0.13964844,\n",
       "       0.11999456, 0.18722318, 0.05942767, 0.23649906, 0.19054358,\n",
       "       0.06130229, 0.29649484])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.meanloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammahat = np.asarray([gammas[cv.bestgamma[i]][0] for i in range(cv.bestgamma.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/paper/trainedmodels/ELleaf_surface_gamma', gammahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "surfaces = {}\n",
    "for m in range(len(major_structure_ids)):\n",
    "    sid = major_structure_ids[m]\n",
    "    surfaces[sid ] = connectivity_data.structure_datas[sid].loss_surface_cv_leaf\n",
    "    surfaces[sid ].gamma = gammahat[m]\n",
    "    \n",
    "with open('/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/paper/trainedmodels/ELleaf_surface.pickle', 'wb') as handle:\n",
    "    pickle.dump(surfaces, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ia_map[ontological_order_leaves[i]] for i in range(len(ontological_order_leaves))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen_010719_5",
   "language": "python",
   "name": "allen_010719_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
