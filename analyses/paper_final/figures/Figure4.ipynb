{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33b3532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/samsonkoelle/mouse_connectivity_models/data/data_final/input_011520.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5j/2xkgvzfs29nfprr5czfm2gtr0000gn/T/ipykernel_47898/2907372536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mINPUT_JSON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkingdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/data_final/input_011520.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mEXPERIMENTS_EXCLUDE_JSON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkingdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/data_final/experiments_exclude.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_JSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0mexperiments_exclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPERIMENTS_EXCLUDE_JSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mmanifest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'manifest_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mcm_class/lib/python3.7/site-packages/allensdk/core/json_utilities.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m\"\"\" Shortcut reading JSON from a file. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# If empty file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/samsonkoelle/mouse_connectivity_models/data/data_final/input_011520.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import gcf\n",
    "import numpy as np \n",
    "from einops import rearrange\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.decomposition import non_negative_factorization\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.decomposition._nmf import NMF\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "import allensdk.core.json_utilities as ju\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "from mcmodels.core import VoxelModelCache\n",
    "from mcmodels.core.utils import get_structure_id,get_ordered_summary_structures\n",
    "from mcmodels.core.connectivity_data import get_connectivity_data\n",
    "from mcmodels.models.voxel.crossvalidation import get_nwloocv_predictions_multimodel_merge_dists\n",
    "from mcmodels.utils import nonzero_unique \n",
    "from mcmodels.core.utils import get_leaves_ontologicalorder, get_indices, get_indices2,get_eval_indices,screen_index_matrices,screen_index_matrices2,screen_index_matrices3,get_indices_2ormore#get_cre_status,get_minorstructure_dictionary,get_leaves_ontologicalorder\n",
    "\n",
    "#load data\n",
    "def cv_nmf_missing(data, n_components,alpha=0.01, l1_ratio = 1.,p_holdout = .3):\n",
    "    \n",
    "    missings = np.asarray(np.where(np.isnan(data))).transpose()\n",
    "    presents = np.asarray(np.where(~np.isnan(data))).transpose()\n",
    "\n",
    "    M = np.where(np.random.rand(presents.shape[0]) > p_holdout)[0]\n",
    "    N = np.where(np.random.rand(presents.shape[0]) < p_holdout)[0]\n",
    "\n",
    "    nmf = NMF(n_components=n_components, alpha=alpha, l1_ratio=l1_ratio, solver='mu', init = 'random', max_iter=500)\n",
    "\n",
    "    data_tr = data.copy()\n",
    "    for i in range(len(M)):\n",
    "        data_tr[presents[M[i],0] ,presents[M[i],1]]  =np.nan\n",
    "\n",
    "    data_te = data.copy()\n",
    "    for i in range(len(N)):\n",
    "        data_te[presents[N[i],0] ,presents[N[i],1]]  =np.nan\n",
    "\n",
    "    nmf.fit(data_tr)\n",
    "\n",
    "    tr_nmf_embedding = nmf.transform(data_tr)\n",
    "    te_nmf_embedding = nmf.transform(data_te)\n",
    "\n",
    "    tr_nmf_recon = nmf.inverse_transform(tr_nmf_embedding)\n",
    "    te_nmf_recon = nmf.inverse_transform(te_nmf_embedding)\n",
    "    tr_err = np.nanmean((data_tr - tr_nmf_recon)**2)\n",
    "    te_err= np.nanmean((data_te - te_nmf_recon)**2)\n",
    "    \n",
    "    return(tr_err, te_err)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        #cmap(np.linspace(maxval, minval, n)))\n",
    "        cmap(np.linspace(minval,maxval , n)))\n",
    "    return new_cmap\n",
    "\n",
    "#arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "#fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "cmap = plt.get_cmap('Greys')\n",
    "new_cmap = truncate_colormap(cmap, 0.1,1.)\n",
    "\n",
    "def fix_pdcsv(csv):\n",
    "    \n",
    "    csv_rownames = np.asarray(csv.iloc[:,0])\n",
    "    csv = csv.iloc[:,1:]\n",
    "    csv.index = csv_rownames\n",
    "    return(csv)\n",
    "\n",
    "def fill_df_na(data, indices):\n",
    "    \n",
    "    for i in range(indices.shape[0]):\n",
    "        data.iloc[indices[i,0],indices[i,1]] = np.nan\n",
    "        \n",
    "    return(data)\n",
    "\n",
    "def get_colors(structures, palettes, alpha):\n",
    "    \n",
    "    strs_unique = np.unique(structures)\n",
    "    nstr = len(strs_unique)\n",
    "    cs = sns.color_palette(\"Spectral\", nstr)\n",
    "    \n",
    "    #print(np.asarray(cs).shape, np.expand_dims(np.ones(12),1).shape)\n",
    "    cs_alphas = np.hstack([np.asarray(cs), alpha*np.expand_dims(np.ones(12),1)])\n",
    "    color_str = {}\n",
    "    for i in range(nstr):\n",
    "        #print(i)\n",
    "        color_str[strs_unique[i]] = cs_alphas[i]\n",
    "    #print(color_str['CB'])\n",
    "    #print(color_str)\n",
    "    output = np.zeros((len(structures),4), dtype  =float)\n",
    "    for i in range(len(structures)):\n",
    "        #print(np.asarray(color_str[structures[i]]))\n",
    "        output[i] = np.asarray(color_str[structures[i]])\n",
    "        \n",
    "    return(output,color_str)\n",
    "\n",
    "\n",
    "\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "TOP_DIR = workingdirectory\n",
    "INPUT_JSON = workingdirectory + '/data/data_final/input_011520.json'\n",
    "EXPERIMENTS_EXCLUDE_JSON = workingdirectory + '/data/data_final/experiments_exclude.json'\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "st = cache.get_structure_tree()\n",
    "ai_map = st.get_id_acronym_map()\n",
    "ia_map = {value: key for key, value in ai_map.items()}\n",
    "major_structures = np.load(workingdirectory + '/analyses/paper_final/metadata/major_structures.npy')\n",
    "major_structure_ids = np.load(workingdirectory + '/analyses/paper_final/metadata/major_structure_ids.npy')\n",
    "data_info = pd.read_excel(workingdirectory + '/data/data_final/Whole Brain Cre Image Series_curation only.xlsx', 'all datasets curated_070919pull')\n",
    "data_info.set_index(\"id\", inplace=True)\n",
    "with open('data/info/leafs.pickle', 'rb') as handle:\n",
    "    leafs = pickle.load(handle)\n",
    "ontological_order_leaves = np.load(workingdirectory + '/analyses/paper_final/metadata/ontological_order_leaves_v3.npy')\n",
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c692958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOP_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "INPUT_JSON = os.path.join(TOP_DIR, 'input_011520.json')\n",
    "EXPERIMENTS_EXCLUDE_JSON = os.path.join(TOP_DIR, 'experiments_exclude.json')\n",
    "FILE_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "OUTPUT_DIR = os.path.join(FILE_DIR, 'output')\n",
    "\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "\n",
    "#its unclear why the hyperparameters are loaded from the output directory\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "major_structures = input_data.get('structures')\n",
    "\n",
    "#wt_conn = pd.read_csv('/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/paper/connectivities/el_leafsurf_leafsmth_leafleaf_meandata_0428_log6.csv',  header=[0,1])\n",
    "wt_conn = pd.read_csv('/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/paper/connectivities/el_leafsurf_leafsmth_leafleaf_C57BL6J0428_log6.csv',  header=[0,1])\n",
    "wt_conn = fix_pdcsv(wt_conn)\n",
    "#dists = pd.read_csv('/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/analyses/paper/getinfo/distances.csv',  header=[0,1])\n",
    "#dists = fix_pdcsv(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e5970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceee45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcm_class",
   "language": "python",
   "name": "mcm_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
