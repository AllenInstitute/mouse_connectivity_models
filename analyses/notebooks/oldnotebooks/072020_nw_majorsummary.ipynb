{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "import allensdk.core.json_utilities as ju\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "from mcmodels.core import Mask,ModelData,VoxelModelCache\n",
    "from mcmodels.core.utils import get_structure_id, get_ordered_summary_structures,get_minorstructures,get_loss_paper\n",
    "from mcmodels.utils import nonzero_unique, unionize\n",
    "from mcmodels.core.experiment import get_voxeldata_msvd\n",
    "from mcmodels.models.crossvalidation import get_best_hyperparameters,get_loss_best_hyp,get_loocv_predictions,get_loss\n",
    "from mcmodels.core.utils import get_cre_status,get_minorstructure_dictionary,get_leaves_ontologicalorder\n",
    "from mcmodels.core.utils import get_regionalized_normalized_data\n",
    "from mcmodels.core.utils import get_connectivity\n",
    "from mcmodels.core.utils import get_ontological_order_leaf\n",
    "from mcmodels.core.utils import get_nw_loocv,get_wt_inds\n",
    "from mcmodels.core.utils import get_countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "TOP_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "INPUT_JSON = os.path.join(TOP_DIR, 'input_011520.json')\n",
    "EXPERIMENTS_EXCLUDE_JSON = os.path.join(TOP_DIR, 'experiments_exclude.json')\n",
    "FILE_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "OUTPUT_DIR = os.path.join(FILE_DIR, 'output')\n",
    "\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "\n",
    "#its unclear why the hyperparameters are loaded from the output directory\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "major_structures = input_data.get('structures')\n",
    "major_structure_ids = [get_structure_id(cache, s) for s in major_structures]\n",
    "data_info = pd.read_excel('/Users/samsonkoelle/alleninstitute/Whole Brain Cre Image Series_curation only.xlsx', 'all datasets curated_070919pull')\n",
    "data_info.set_index(\"id\", inplace=True)\n",
    "ontological_order = get_ordered_summary_structures(cache)\n",
    "\n",
    "mcc = MouseConnectivityCache(manifest_file = '../connectivity/mouse_connectivity_manifest.json')\n",
    "st = mcc.get_structure_tree()\n",
    "ai_map = st.get_id_acronym_map()\n",
    "ia_map = {value: key for key, value in ai_map.items()}\n",
    "\n",
    "#regionalize voxel model: compare with regional model\n",
    "#regional parameters\n",
    "cre = None\n",
    "eid_set=None\n",
    "high_res=False\n",
    "threshold_injection = False\n",
    "\n",
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]\n",
    "#cre= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "None\n",
      "703\n",
      "None\n",
      "1089\n",
      "None\n",
      "1097\n",
      "None\n",
      "315\n",
      "None\n",
      "313\n",
      "None\n",
      "354\n",
      "None\n",
      "698\n",
      "None\n",
      "771\n",
      "None\n",
      "803\n",
      "None\n",
      "477\n",
      "None\n",
      "549\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "msvds = {}\n",
    "#gammas = np.asarray([0.1])\n",
    "for sid in major_structure_ids:\n",
    "    print(sid)\n",
    "    voxel_data = ModelData(cache, sid)\n",
    "    print(cre)\n",
    "    experiment_ids = voxel_data.get_experiment_ids(experiments_exclude=experiments_exclude, cre=cre)\n",
    "    experiment_ids = np.asarray(list(experiment_ids))    \n",
    "    msvd = get_voxeldata_msvd(cache, sid,experiments_exclude,default_structure_ids,cre)\n",
    "    #msvd.l2losses, msvd.paperlosses,msvd.normspredict,msvd.normtrue = single_region_cv(msvd, gammas)\n",
    "    msvds[sid]  = msvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creline = get_cre_status(data_info, msvds)\n",
    "experiments_minor_structures = get_minorstructure_dictionary(msvds, data_info)\n",
    "leavves = get_leaves_ontologicalorder(msvd, ontological_order)\n",
    "\n",
    "# contra_key = msvd.experiments[list(msvd.experiments.keys())[0]].projection_mask.get_key(structure_ids=leavves, hemisphere_id=1)\n",
    "# ipsi_key = msvd.experiments[list(msvd.experiments.keys())[0]].projection_mask.get_key(structure_ids=leavves, hemisphere_id=2)\n",
    "\n",
    "key = list(msvd.experiments.keys())[0]\n",
    "contra_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=1)\n",
    "ipsi_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=2)\n",
    "\n",
    "msvds = get_regionalized_normalized_data(msvds,cache, ontological_order,ipsi_key,contra_key,experiments_minor_structures)\n",
    "gammas = np.asarray([0.1,.5,1,2,10])\n",
    "wt_2ormore = get_wt_inds(creline)\n",
    "\n",
    "for sid in major_structure_ids:\n",
    "    #print(msvds[sid].projections.shape[0], len(wt_2ormore[sid]))\n",
    "    msvds[sid].loocv_predictions_all = get_nw_loocv(msvds[sid], np.asarray(list(range(msvds[sid].projections.shape[0]))), get_loocv_predictions, gammas)\n",
    "    msvds[sid].loocv_predictions_wt = get_nw_loocv(msvds[sid], wt_2ormore[sid], get_loocv_predictions, gammas)\n",
    "\n",
    "homo_loocv_predictions_all = {}\n",
    "homo_loocv_predictions_wt = {}\n",
    "homo_reg_proj_vcount_norm_renorms= {}\n",
    "for sid in major_structure_ids:\n",
    "    homo_loocv_predictions_all[sid ] = msvds[sid].loocv_predictions_all\n",
    "    homo_loocv_predictions_wt[sid ] = msvds[sid].loocv_predictions_wt\n",
    "    homo_reg_proj_vcount_norm_renorms[sid ] = msvds[sid].reg_proj_vcount_norm_renorm\n",
    "    \n",
    "inds_good = {}\n",
    "for sid in major_structure_ids:\n",
    "    inds_good[sid] = np.asarray(list(range(msvds[sid].injections.shape[0])))\n",
    "    \n",
    "a= [list(range(5))]\n",
    "keys = np.asarray(list(itertools.product(*a)))\n",
    "\n",
    "#sel_ga_wt = get_best_hyperparameters(losses_wts,keys)\n",
    "\n",
    "losses_all = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = inds_good, true_ind = inds_good,keys = keys)\n",
    "losses_wts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_wt,pred_ind = wt_2ormore, true_ind = wt_2ormore, keys = keys)\n",
    "losses_allwts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = wt_2ormore, true_ind = wt_2ormore, keys = keys)\n",
    "\n",
    "sel_ga_all = get_best_hyperparameters(losses_all,keys)\n",
    "sel_ga_allwt = sel_ga_all#get_gamma(losses_allwt,keys)\n",
    "\n",
    "mean_nw_all = get_loss_best_hyp(losses_all, sel_ga_all)\n",
    "mean_nw_allwt = get_loss_best_hyp(losses_allwts, sel_ga_all)\n",
    "#mean_nw_wt = get_loss_best_hyp(losses_all, sel_ga_wt)\n",
    "\n",
    "print(mean_nw_all)\n",
    "print(mean_nw_allwt)\n",
    "\n",
    "losses = np.asarray([mean_nw_all, \n",
    "           mean_nw_allwt]).transpose()\n",
    "losses2 = losses[[4,7,2,1,10,9,11,3,5,8,6,0]]\n",
    "loss =pd.DataFrame(losses2, columns = ['all','allwt'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen_010719_5",
   "language": "python",
   "name": "allen_010719_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
