{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "import allensdk.core.json_utilities as ju\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "\n",
    "from mcmodels.core import Mask,ModelData,VoxelModelCache\n",
    "from mcmodels.core.utils import get_structure_id, get_ordered_summary_structures,get_minorstructures,get_loss_paper\n",
    "from mcmodels.utils import nonzero_unique, unionize\n",
    "from mcmodels.core.experiment import get_voxeldata_msvd\n",
    "from mcmodels.models.crossvalidation import get_best_hyperparameters,get_loss_best_hyp,get_loocv_predictions,get_loss\n",
    "from mcmodels.core.utils import get_cre_status,get_minorstructure_dictionary,get_leaves_ontologicalorder\n",
    "from mcmodels.core.utils import get_regionalized_normalized_data\n",
    "from mcmodels.core.utils import get_connectivity\n",
    "from mcmodels.core.utils import get_ontological_order_leaf\n",
    "from mcmodels.core.utils import get_nw_loocv,get_wt_inds\n",
    "from mcmodels.core.utils import get_countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "TOP_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "INPUT_JSON = os.path.join(TOP_DIR, 'input_011520.json')\n",
    "EXPERIMENTS_EXCLUDE_JSON = os.path.join(TOP_DIR, 'experiments_exclude.json')\n",
    "FILE_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "OUTPUT_DIR = os.path.join(FILE_DIR, 'output')\n",
    "\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "\n",
    "#its unclear why the hyperparameters are loaded from the output directory\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "major_structures = input_data.get('structures')\n",
    "major_structure_ids = [get_structure_id(cache, s) for s in major_structures]\n",
    "data_info = pd.read_excel('/Users/samsonkoelle/alleninstitute/Whole Brain Cre Image Series_curation only.xlsx', 'all datasets curated_070919pull')\n",
    "data_info.set_index(\"id\", inplace=True)\n",
    "ontological_order = get_ordered_summary_structures(cache)\n",
    "\n",
    "mcc = MouseConnectivityCache(manifest_file = '../connectivity/mouse_connectivity_manifest.json')\n",
    "st = mcc.get_structure_tree()\n",
    "ai_map = st.get_id_acronym_map()\n",
    "ia_map = {value: key for key, value in ai_map.items()}\n",
    "\n",
    "#regionalize voxel model: compare with regional model\n",
    "#regional parameters\n",
    "cre = None\n",
    "eid_set=None\n",
    "high_res=False\n",
    "threshold_injection = False\n",
    "\n",
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]\n",
    "#cre= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "None\n",
      "703\n",
      "None\n",
      "1089\n",
      "None\n",
      "1097\n",
      "None\n",
      "315\n",
      "None\n",
      "313\n",
      "None\n",
      "354\n",
      "None\n",
      "698\n",
      "None\n",
      "771\n",
      "None\n",
      "803\n",
      "None\n",
      "477\n",
      "None\n",
      "549\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "msvds = {}\n",
    "#gammas = np.asarray([0.1])\n",
    "for sid in major_structure_ids:\n",
    "    print(sid)\n",
    "    voxel_data = ModelData(cache, sid)\n",
    "    print(cre)\n",
    "    experiment_ids = voxel_data.get_experiment_ids(experiments_exclude=experiments_exclude, cre=cre)\n",
    "    experiment_ids = np.asarray(list(experiment_ids))    \n",
    "    msvd = get_voxeldata_msvd(cache, sid,experiments_exclude,default_structure_ids,cre)\n",
    "    #msvd.l2losses, msvd.paperlosses,msvd.normspredict,msvd.normtrue = single_region_cv(msvd, gammas)\n",
    "    msvds[sid]  = msvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_nw_loocv(msvd, indices, loocv, hyperparameters):\n",
    "\n",
    "    if len(indices) > 1:\n",
    "        projections = msvd.reg_proj_vcount_norm_renorm\n",
    "        centroids = msvd.centroids\n",
    "        nreg = projections.shape[1]\n",
    "        nexp = projections.shape[0]\n",
    "        nhyp = hyperparameters.shape[0]\n",
    "        loocv_predictions = np.zeros((nhyp, nexp, nreg))\n",
    "        for g in range(nhyp):\n",
    "            loocv_predictions[g, indices] = loocv(projections[indices], centroids[indices], hyperparameters[g])\n",
    "        return (loocv_predictions)\n",
    "    else:\n",
    "        return (np.asarray([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_homo_loocv(msvd, indices, loocv, hyperparameters):\n",
    "\n",
    "    if len(indices) > 1:\n",
    "        projections = msvd.reg_proj_vcount_norm_renorm\n",
    "        injections = msvd.reg_inj_vcount_norm / np.expand_dims(np.linalg.norm(msvd.reg_inj_vcount_norm, axis = 1),1)\n",
    "        injections[np.where(np.isnan(injections))] = 0.\n",
    "        \n",
    "        nreg = projections.shape[1]\n",
    "        nexp = projections.shape[0]\n",
    "        nhyp = hyperparameters.shape[0]\n",
    "        loocv_predictions = np.zeros((nhyp, nexp, nreg))\n",
    "        for g in range(nhyp):\n",
    "            loocv_predictions[g, indices] = loocv(projections[indices], injections[indices], *hyperparameters[g])\n",
    "        return (loocv_predictions)\n",
    "    else:\n",
    "        return (np.asarray([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "703\n",
      "1089\n",
      "1097\n",
      "315\n",
      "313\n",
      "354\n",
      "698\n",
      "771\n",
      "803\n",
      "477\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "creline = get_cre_status(data_info, msvds)\n",
    "experiments_minor_structures = get_minorstructure_dictionary(msvds, data_info)\n",
    "leavves = get_leaves_ontologicalorder(msvd, ontological_order)\n",
    "\n",
    "# contra_key = msvd.experiments[list(msvd.experiments.keys())[0]].projection_mask.get_key(structure_ids=leavves, hemisphere_id=1)\n",
    "# ipsi_key = msvd.experiments[list(msvd.experiments.keys())[0]].projection_mask.get_key(structure_ids=leavves, hemisphere_id=2)\n",
    "\n",
    "key = list(msvd.experiments.keys())[0]\n",
    "contra_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=1)\n",
    "ipsi_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=2)\n",
    "\n",
    "msvds = get_regionalized_normalized_data(msvds,cache, ontological_order,ipsi_key,contra_key,experiments_minor_structures)\n",
    "thres_ncomp = np.asarray([[1e-10,0]])\n",
    "wt_2ormore = get_wt_inds(creline)\n",
    "\n",
    "for sid in major_structure_ids:\n",
    "    print(sid)\n",
    "    #print(msvds[sid].projections.shape[0], len(wt_2ormore[sid]))\n",
    "    msvds[sid].loocv_predictions_all = get_homo_loocv(msvds[sid], np.asarray(list(range(msvds[sid].projections.shape[0]))), get_loocv_predictions_nnlinear_number_inj, thres_ncomp)\n",
    "    msvds[sid].loocv_predictions_wt = get_homo_loocv(msvds[sid], wt_2ormore[sid], get_loocv_predictions_nnlinear_number_inj, thres_ncomp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mcmodels.models.crossvalidation import get_loocv_predictions_nnlinear_number_inj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "homo_loocv_predictions_all = {}\n",
    "homo_loocv_predictions_wt = {}\n",
    "homo_reg_proj_vcount_norm_renorms= {}\n",
    "for sid in major_structure_ids:\n",
    "    homo_loocv_predictions_all[sid ] = msvds[sid].loocv_predictions_all\n",
    "    homo_loocv_predictions_wt[sid ] = msvds[sid].loocv_predictions_wt\n",
    "    homo_reg_proj_vcount_norm_renorms[sid ] = msvds[sid].reg_proj_vcount_norm_renorm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 577 is out of bounds for axis 0 with size 577",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a844a81528ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#sel_ga_wt = get_best_hyperparameters(losses_wts,keys)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlosses_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomo_reg_proj_vcount_norm_renorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhomo_loocv_predictions_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minds_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minds_good\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlosses_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomo_reg_proj_vcount_norm_renorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhomo_loocv_predictions_wt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt_2ormore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt_2ormore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlosses_allwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomo_reg_proj_vcount_norm_renorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhomo_loocv_predictions_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt_2ormore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt_2ormore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(true_dict, prediction_dict, pred_ind, true_ind, keys)\u001b[0m\n\u001b[1;32m    191\u001b[0m             output[sid][tuple(keys[j])] = np.asarray(\n\u001b[1;32m    192\u001b[0m                 [get_loss_paper(true_dict[sid][tind[i]], prediction_dict[sid][tuple(keys[j])][pind[i]]) for i in\n\u001b[0;32m--> 193\u001b[0;31m                  range(nexp)])\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             output[sid][tuple(keys[j])] = np.asarray(\n\u001b[0;32m--> 192\u001b[0;31m                 [get_loss_paper(true_dict[sid][tind[i]], prediction_dict[sid][tuple(keys[j])][pind[i]]) for i in\n\u001b[0m\u001b[1;32m    193\u001b[0m                  range(nexp)])\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 577 is out of bounds for axis 0 with size 577"
     ]
    }
   ],
   "source": [
    "\n",
    "inds_good = {}\n",
    "for sid in major_structure_ids:\n",
    "    inds_good[sid] = np.asarray(list(range(msvds[sid].injections.shape[0])))\n",
    "    \n",
    "a = [list(range(1)), list(range(1))]\n",
    "keys = np.asarray(list(itertools.product(*a)))\n",
    "#keys = np.asarray([list(range(keys.shape[0]))])\n",
    "#sel_ga_wt = get_best_hyperparameters(losses_wts,keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_loss(true_dict, prediction_dict, pred_ind=None, true_ind=None, keys=None):\n",
    "    output = {}\n",
    "    \n",
    "    major_structure_ids = list(prediction_dict.keys())\n",
    "    nms = len(major_structure_ids)\n",
    "    ngam = prediction_dict[major_structure_ids[0]].shape[0]\n",
    "    nalph = prediction_dict[major_structure_ids[0]].shape[1]\n",
    "    for m in range(nms):\n",
    "        sid = major_structure_ids[m]\n",
    "        if pred_ind == None:\n",
    "            # prediction_dict and true_dict will contain predictions for 'bad' experiments with no recorded injection\n",
    "            # when we have the wild type predictions, the subset is what is good among the wild types\n",
    "            # so 'true' subsetting is always good, since it is w.r.t. the full injection\n",
    "            # but prediction needs good w.r.t. wt\n",
    "            pind = np.asarray(list(range(prediction_dict[sid].shape[1])), dtype=int)\n",
    "        else:\n",
    "            pind = pred_ind[sid]\n",
    "        if true_ind == None:\n",
    "            tind = np.asarray(list(range(true_dict[sid].shape[0])), dtype=int)\n",
    "        else:\n",
    "            tind = true_ind[sid]\n",
    "\n",
    "        nexp = len(pind)\n",
    "\n",
    "        output[sid] = np.zeros((keys.shape[0], nexp))\n",
    "\n",
    "        for j in range(keys.shape[0]):\n",
    "            output[sid][j] = np.asarray(\n",
    "                [get_loss_paper(true_dict[sid][tind[i]], prediction_dict[sid][j][pind[i]]) for i in\n",
    "                 range(nexp)])\n",
    "\n",
    "    return (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_all = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = inds_good, true_ind = inds_good,keys = keys)\n",
    "losses_wts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_wt,pred_ind = wt_2ormore, true_ind = wt_2ormore, keys = keys)\n",
    "losses_allwts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = wt_2ormore, true_ind = wt_2ormore, keys = keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 577)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_loocv_predictions_all[512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "[0.82586542 0.9774093  0.36677618 0.31101535 0.4733092  0.55434449\n",
      " 0.61482932 0.48790106 0.67638543 0.65341301 0.79833544 0.44472639]\n",
      "[0.94851362        nan 0.27999305 0.4124781  0.35959949 0.57967312\n",
      " 0.9335947  0.41186078 0.69060817 0.42127543 0.6619159  0.30344883]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:221: RuntimeWarning: Mean of empty slice\n",
      "  output[m] = np.nanmean(losses[sid][hyps[m], :])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sel_ga_all = get_best_hyperparameters(losses_all,keys)\n",
    "sel_ga_allwt = sel_ga_all#get_gamma(losses_allwt,keys)\n",
    "\n",
    "mean_nw_all = get_loss_best_hyp(losses_all, sel_ga_all)\n",
    "mean_nw_allwt = get_loss_best_hyp(losses_allwts, sel_ga_all)\n",
    "#mean_nw_wt = get_loss_best_hyp(losses_all, sel_ga_wt)\n",
    "\n",
    "print(mean_nw_all)\n",
    "print(mean_nw_allwt)\n",
    "\n",
    "losses = np.asarray([mean_nw_all, \n",
    "           mean_nw_allwt]).transpose()\n",
    "losses2 = losses[[4,7,2,1,10,9,11,3,5,8,6,0]]\n",
    "loss =pd.DataFrame(losses2, columns = ['all','allwt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'majorsum_homo_0720'\n",
    "expfolder = workingdirectory +   '/data/' + name\n",
    "os.mkdir(expfolder)\n",
    "loss.to_csv(expfolder + 'losses')\n",
    "\n",
    "#msvds_save = {}\n",
    "for sid in major_structure_ids:\n",
    "    np.save(expfolder +'/'+ str(sid) + 'reg_proj_vcount_norm_renorm',msvds[sid].reg_proj_vcount_norm_renorm)\n",
    "    np.save(expfolder +'/'+ str(sid) + 'loocv_predictions_all',msvds[sid].loocv_predictions_all)\n",
    "    np.save(expfolder +'/'+ str(sid) + 'loocv_predictions_wt',msvds[sid].loocv_predictions_wt)\n",
    "    \n",
    "with open(expfolder +'/'+ 'wt_2ormore_base.pickle', 'wb') as handle:\n",
    "    pickle.dump(wt_2ormore, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('data/info/leafs.pickle', 'rb') as handle:\n",
    "    leafs = pickle.load(handle)\n",
    "    \n",
    "#ontological_order_leaf = get_ontological_order_leaf(leafs, ontological_order, st)\n",
    "#source_exp_countvec, source_exp_countvec_wt = get_countvec(ontological_order, ia_map, creline, experiments_minor_structures)\n",
    "#hyperparameters = gammas[sel_ga_all]\n",
    "#leavves v ontological_order_leaf\n",
    "#leavves is the leaves associated with ontological_order\n",
    "#ontological_order_leaf is the leaves that are actually present\n",
    "#leafs is the dictionary with the leaves of the experiments\n",
    "#df = get_connectivity(msvds, cache, ia_map, hyperparameters, ontological_order_leaf, ontological_order, leafs, creline,experiments_minor_structures, ipsi_key, contra_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters =thres_ncomp\n",
    "# indices = np.asarray(list(range(msvds[sid].projections.shape[0])))\n",
    "# msvd = msvds[sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if len(indices) > 1:\n",
    "#         projections = msvd.reg_proj_vcount_norm_renorm\n",
    "#         injections = msvd.reg_inj_vcount_norm / np.expand_dims(np.linalg.norm(msvd.reg_inj_vcount_norm, axis = 1),1)\n",
    "#         injections[np.where(np.isnan(injections))] = 0.\n",
    "        \n",
    "#         nreg = projections.shape[1]\n",
    "#         nexp = projections.shape[0]\n",
    "#         nhyp = hyperparameters.shape[0]\n",
    "#         loocv_predictions = np.zeros((nhyp, nexp, nreg))\n",
    "#         for g in range(nhyp):\n",
    "#             loocv_predictions[g, indices] = get_loocv_predictions_nnlinear_number_inj(projections[indices], injections[indices], *hyperparameters[g])\n",
    "#         #return (loocv_predictions)\n",
    "#     else:\n",
    "#         2+2\n",
    "#         #return (np.asarray([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-10, 0.e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.37970339e-03, 2.98649993e-05, 1.32495100e-02, ...,\n",
       "        7.23178018e-05, 1.21523750e-04, 9.72360067e-05],\n",
       "       [1.94261614e-02, 1.84335659e-05, 4.46369778e-03, ...,\n",
       "        0.00000000e+00, 8.17640903e-05, 1.34749070e-03],\n",
       "       [2.73950435e-02, 1.19056692e-02, 5.60228727e-05, ...,\n",
       "        5.72578028e-06, 1.03043303e-05, 3.50847782e-04],\n",
       "       ...,\n",
       "       [5.06741181e-03, 2.41173602e-05, 1.96433789e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.05604068e-04],\n",
       "       [3.45455036e-02, 1.45014897e-02, 4.23544261e-05, ...,\n",
       "        6.50257243e-06, 1.54651425e-05, 5.33802784e-04],\n",
       "       [9.55329233e-05, 4.14985407e-05, 1.31462144e-07, ...,\n",
       "        1.79815256e-08, 4.32830056e-08, 1.48560673e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loocv_predictions_nnlinear_number_inj(projections[indices], injections[indices], *hyperparameters[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-19-870c7af242e9>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-870c7af242e9>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "*hyperparameters[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.37970339e-03, 2.98649993e-05, 1.32495100e-02, ...,\n",
       "        7.23178018e-05, 1.21523750e-04, 9.72360067e-05],\n",
       "       [1.94261614e-02, 1.84335659e-05, 4.46369778e-03, ...,\n",
       "        0.00000000e+00, 8.17640903e-05, 1.34749070e-03],\n",
       "       [2.73950435e-02, 1.19056692e-02, 5.60228727e-05, ...,\n",
       "        5.72578028e-06, 1.03043303e-05, 3.50847782e-04],\n",
       "       ...,\n",
       "       [5.06741181e-03, 2.41173602e-05, 1.96433789e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.05604068e-04],\n",
       "       [3.45455036e-02, 1.45014897e-02, 4.23544261e-05, ...,\n",
       "        6.50257243e-06, 1.54651425e-05, 5.33802784e-04],\n",
       "       [9.55329233e-05, 4.14985407e-05, 1.31462144e-07, ...,\n",
       "        1.79815256e-08, 4.32830056e-08, 1.48560673e-06]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loocv_predictions_nnlinear_number_inj(projections[indices], injections[indices], hyperparameters[g][0], hyperparameters[g][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen_010719_5",
   "language": "python",
   "name": "allen_010719_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
