{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "workingdirectory = os.popen('git rev-parse --show-toplevel').read()[:-1]\n",
    "sys.path.append(workingdirectory)\n",
    "os.chdir(workingdirectory)\n",
    "\n",
    "import allensdk.core.json_utilities as ju\n",
    "#import mcmodels\n",
    "from mcmodels.core import VoxelModelCache#.voxel_model_cache import VoxelModelCache\n",
    "from mcmodels.core import Mask\n",
    "from mcmodels.core.utils import get_structure_id, get_ordered_summary_structures\n",
    "from mcmodels.utils import nonzero_unique, unionize\n",
    "from mcmodels.core.utils import get_minorstructures\n",
    "from mcmodels.models.crossvalidation import get_loocv_predictions\n",
    "from mcmodels.core.utils import get_loss_paper\n",
    "from mcmodels.core.experiment import get_voxeldata_msvd\n",
    "from mcmodels.core.utils import get_loss_paper\n",
    "\n",
    "from mcmodels.core import ModelData\n",
    "#from VoxelModel import VoxelModel\n",
    "#from HomogeneousModel import HomogeneousModel\n",
    "\n",
    "#from NadarayaWatson import NadarayaWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "TOP_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "INPUT_JSON = os.path.join(TOP_DIR, 'input_011520.json')\n",
    "EXPERIMENTS_EXCLUDE_JSON = os.path.join(TOP_DIR, 'experiments_exclude.json')\n",
    "FILE_DIR = '/Users/samsonkoelle/alleninstitute/mcm_2020/mcm_updated/'\n",
    "OUTPUT_DIR = os.path.join(FILE_DIR, 'output')\n",
    "\n",
    "input_data = ju.read(INPUT_JSON)\n",
    "manifest_file = input_data.get('manifest_file')\n",
    "manifest_file = os.path.join(TOP_DIR, manifest_file)\n",
    "experiments_exclude = ju.read(EXPERIMENTS_EXCLUDE_JSON)\n",
    "\n",
    "#its unclear why the hyperparameters are loaded from the output directory\n",
    "cache = VoxelModelCache(manifest_file=manifest_file)\n",
    "major_structures = input_data.get('structures')\n",
    "major_structure_ids = [get_structure_id(cache, s) for s in major_structures]\n",
    "\n",
    "#regionalize voxel model: compare with regional model\n",
    "#regional parameters\n",
    "cre = None\n",
    "eid_set=None\n",
    "high_res=False\n",
    "threshold_injection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COARSE_STRUCTURE_SET_ID = 2\n",
    "DEFAULT_STRUCTURE_SET_IDS = tuple([COARSE_STRUCTURE_SET_ID])\n",
    "tree = cache.get_structure_tree()\n",
    "default_structures = tree.get_structures_by_set_id(DEFAULT_STRUCTURE_SET_IDS)\n",
    "default_structure_ids = [st['id'] for st in default_structures if st['id'] != 934]\n",
    "#cre= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "None\n",
      "703\n",
      "None\n",
      "1089\n",
      "None\n",
      "1097\n",
      "None\n",
      "315\n",
      "None\n",
      "313\n",
      "None\n",
      "354\n",
      "None\n",
      "698\n",
      "None\n",
      "771\n",
      "None\n",
      "803\n",
      "None\n",
      "477\n",
      "None\n",
      "549\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "msvds = {}\n",
    "#gammas = np.asarray([0.1])\n",
    "for sid in major_structure_ids:\n",
    "    print(sid)\n",
    "    voxel_data = ModelData(cache, sid)\n",
    "    print(cre)\n",
    "    experiment_ids = voxel_data.get_experiment_ids(experiments_exclude=experiments_exclude, cre=cre)\n",
    "    experiment_ids = np.asarray(list(experiment_ids))    \n",
    "    msvd = get_voxeldata_msvd(cache, sid,experiments_exclude,default_structure_ids,cre)\n",
    "    #msvd.l2losses, msvd.paperlosses,msvd.normspredict,msvd.normtrue = single_region_cv(msvd, gammas)\n",
    "    msvds[sid]  = msvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_info = pd.read_excel('/Users/samsonkoelle/alleninstitute/Whole Brain Cre Image Series_curation only.xlsx', 'all datasets curated_070919pull')\n",
    "data_info.set_index(\"id\", inplace=True)\n",
    "ontological_order = get_ordered_summary_structures(cache)\n",
    "\n",
    "exps = np.asarray(data_info.index.values , dtype = np.int)\n",
    "creline = {}\n",
    "for sid in major_structure_ids:\n",
    "    msvd = msvds[sid]\n",
    "    experiment_ids = np.asarray(list(msvd.experiments.keys()))\n",
    "    nexp = len(experiment_ids)\n",
    "    creline[sid] = np.zeros(nexp, dtype = object)\n",
    "    for i in range(len(experiment_ids)):\n",
    "        index = np.where(exps == experiment_ids[i])[0][0]\n",
    "        creline[sid][i] = data_info['transgenic-line'].iloc[index]\n",
    "        \n",
    "experiments_minor_structures = {}\n",
    "for sid in major_structure_ids:\n",
    "    msvd = msvds[sid]\n",
    "    eids = np.asarray(list(msvd.experiments.keys()))\n",
    "    experiments_minor_structures[sid] = get_minorstructures(eids, data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = list(msvd.experiments.keys())[0]\n",
    "contra_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=1)\n",
    "ipsi_key = msvd.experiments[key].projection_mask.get_key(structure_ids=ontological_order, hemisphere_id=2)\n",
    "\n",
    "cre = None\n",
    "l2losses = {}\n",
    "paperlosses = {}\n",
    "normspredict = {}\n",
    "normtrue = {}\n",
    "for sid in major_structure_ids:\n",
    "    #print()\n",
    "    msvd = msvds[sid]\n",
    "    nexp = msvd.projections.shape[0]\n",
    "    ngam = 1\n",
    "    \n",
    "    l2losses[sid] = np.zeros((ngam,nexp))\n",
    "    paperlosses[sid] = np.zeros((ngam,nexp))\n",
    "    normspredict[sid] = np.zeros((ngam,nexp))\n",
    "    normtrue[sid] = np.zeros(nexp)\n",
    "\n",
    "    minor_structures = np.unique(experiments_minor_structures[sid])\n",
    "    nmins = len(minor_structures)\n",
    "    \n",
    "    projections = msvd.projections\n",
    "    ipsi_proj = unionize(projections, ipsi_key)\n",
    "    contra_proj = unionize(projections, contra_key)\n",
    "    reg_proj = np.hstack([ipsi_proj, contra_proj])\n",
    "    msvd.reg_proj = reg_proj\n",
    "    \n",
    "    ipsi_target_regions, ipsi_target_counts = nonzero_unique(ipsi_key, return_counts=True)\n",
    "    contra_target_regions, contra_target_counts = nonzero_unique(contra_key, return_counts=True)\n",
    "    target_counts = np.concatenate([ipsi_target_counts, contra_target_counts])\n",
    "    reg_proj_vcount_norm = np.divide(reg_proj, target_counts[np.newaxis, :])\n",
    "    msvd.reg_proj_vcount_norm = reg_proj_vcount_norm\n",
    "\n",
    "\n",
    "    source_mask = Mask.from_cache(cache, structure_ids=[sid], hemisphere_id=2)\n",
    "    source_key = source_mask.get_key(structure_ids=ontological_order)  \n",
    "    source_target_counts, source_target_counts =nonzero_unique(source_key, return_counts=True)\n",
    "    \n",
    "    injections = msvd.injections\n",
    "    reg_ipsi_inj = unionize(injections, source_key)\n",
    "    msvd.reg_inj = reg_ipsi_inj  \n",
    "    reg_inj_vcount_norm = np.divide(reg_ipsi_inj, source_target_counts[np.newaxis, :])\n",
    "    msvd.reg_inj_vcount_norm = reg_inj_vcount_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "major_structures = input_data.get('structures')\n",
    "major_structure_ids = [get_structure_id(cache, s) for s in major_structures]\n",
    "#gammas = np.asarray([0.1,.5,1,2,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammas = np.asarray([0.1,.5,1,2,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: overflow encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: overflow encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: overflow encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: overflow encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n",
      "0 g\n",
      "1 g\n",
      "2 g\n",
      "3 g\n",
      "4 g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n",
      "/Users/samsonkoelle/alleninstitute/sambranch/mouse_connectivity_models/mcmodels/models/crossvalidation.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_i = weights[i] / weights[i][otherindices].sum()\n"
     ]
    }
   ],
   "source": [
    "nms = len(major_structure_ids)\n",
    "ngam = len(gammas)\n",
    "wt_2ormore = {}\n",
    "losses_reg_norm = np.zeros((nms,ngam))\n",
    "for m in range(12):\n",
    "    sid = major_structure_ids[m]\n",
    "    projections = msvds[sid].reg_proj_vcount_norm\n",
    "    projections = projections / np.expand_dims(np.linalg.norm(projections, axis = 1),1)\n",
    "    msvds[sid].reg_proj_vcount_norm_renorm = projections\n",
    "    centroids = msvds[sid].centroids\n",
    "    nreg = projections.shape[1]\n",
    "    nexp = projections.shape[0]\n",
    "    \n",
    "    nfeat = projections.shape[1]\n",
    "    #ncomps = np.append(np.asarray(np.linspace(1, nfeat / 10, 5), dtype = int),nfeat - 1)\n",
    "    #nalpha = len(alphas)\n",
    "    \n",
    "    #msvds[sid].loocv_predictions_all = np.zeros((ngam, len(ncomps),nalpha, nexp, nreg))\n",
    "    #msvds[sid].loocv_predictions_wt = np.zeros((ngam, len(ncomps),nalpha, nexp, nreg))\n",
    "    msvds[sid].loocv_predictions_wt = np.zeros((ngam, nexp, nreg))\n",
    "    msvds[sid].loocv_predictions_all = np.zeros((ngam, nexp, nreg))\n",
    "    wt_inds = np.where(creline[sid] == 'C57BL/6J')[0]\n",
    "    wt_2ormore[sid] = np.asarray([])\n",
    "    \n",
    "    \n",
    "    for g in range(ngam):\n",
    "        print(g,'g')\n",
    "        #for c in range(len(ncomps)):\n",
    "#            print(c,'c')\n",
    "            #for a in range(nalpha):\n",
    "#                print(a,'a')\n",
    "#         losses_reg_norm[m,g] = get_loss_paper(projections[wt_inds], loocv_predictions[wt_inds])\n",
    "        msvds[sid].loocv_predictions_all[g] = get_loocv_predictions(projections, centroids, gammas[g])\n",
    "        if len(wt_inds) > 1:\n",
    "            msvds[sid].loocv_predictions_wt[g, wt_inds] = get_loocv_predictions(projections[wt_inds], centroids[wt_inds], gammas[g])\n",
    "            if g == 0:\n",
    "                wt_2ormore[sid] = np.append(wt_2ormore[sid],wt_inds)\n",
    "    wt_2ormore[sid] = np.asarray(wt_2ormore[sid], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exps = np.asarray(data_info.index.values , dtype = np.int)\n",
    "creline = {}\n",
    "for sid in major_structure_ids:\n",
    "    msvd = msvds[sid]\n",
    "    experiment_ids = np.asarray(list(msvd.experiments.keys()))\n",
    "    nexp = len(experiment_ids)\n",
    "    creline[sid] = np.zeros(nexp, dtype = object)\n",
    "    for i in range(len(experiment_ids)):\n",
    "        index = np.where(exps == experiment_ids[i])[0][0]\n",
    "        creline[sid][i] = data_info['transgenic-line'].iloc[index]\n",
    "\n",
    "#inds_bad are where there is no injection\n",
    "#we can use these to train but shouldnt to evaluate\n",
    "#the 'wt_ind' should just be 'eval_ind'\n",
    "inds_bad = {}\n",
    "inds_good = {}\n",
    "for sid in major_structure_ids:\n",
    "    injections = msvds[sid].injections \n",
    "    inds_bad[sid] = np.where(injections.sum(axis = 1) == 0.)[0]\n",
    "    inds_good[sid] = np.where(injections.sum(axis = 1) > 0.)[0]\n",
    "    \n",
    "nms = len(major_structure_ids)\n",
    "#ngam = len(gammas)\n",
    "wt_2ormore = {}\n",
    "losses_reg_norm = np.zeros((nms,ngam))\n",
    "inds_good_wt = {}\n",
    "inds_good_wtsub = {}\n",
    "for m in range(nms):\n",
    "    sid = major_structure_ids[m]\n",
    "    wt_inds = np.where(creline[sid] == 'C57BL/6J')[0]\n",
    "    wt_2ormore[sid] = np.asarray([])\n",
    "    #wt_2ormore is the indices of when there are 2 or more wild types\n",
    "    if len(wt_inds) > 1:\n",
    "        wt_2ormore[sid] = np.append(wt_2ormore[sid],wt_inds)\n",
    "    wt_2ormore[sid] = np.asarray(wt_2ormore[sid], dtype = int)\n",
    "    inds_good_wt[sid] = np.intersect1d(wt_2ormore[sid], inds_good[sid])\n",
    "    inds_good_wtsub[sid] = np.where(np.isin(wt_2ormore[sid], inds_good[sid]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def get_loss(true_dict, prediction_dict,pred_ind = None, true_ind = None, keys = None):\n",
    "    \n",
    "    output = {}\n",
    "    major_structure_ids = list(prediction_dict.keys())\n",
    "    nms = len(major_structure_ids)\n",
    "    ngam = prediction_dict[major_structure_ids[0]].shape[0]\n",
    "    nalph = prediction_dict[major_structure_ids[0]].shape[1]\n",
    "    for m in range(nms):\n",
    "        sid = major_structure_ids[m]\n",
    "        if pred_ind == None:\n",
    "            #prediction_dict and true_dict will contain predictions for 'bad' experiments with no recorded injection\n",
    "            #when we have the wild type predictions, the subset is what is good among the wild types\n",
    "            #so 'true' subsetting is always good, since it is w.r.t. the full injection\n",
    "            #but prediction needs good w.r.t. wt\n",
    "            pind = np.asarray(list(range(prediction_dict[sid].shape[1])), dtype = int)\n",
    "        else:\n",
    "            pind = pred_ind[sid]\n",
    "        if true_ind == None:\n",
    "            tind = np.asarray(list(range(true_dict[sid].shape[0])), dtype = int)\n",
    "        else:\n",
    "            tind = true_ind[sid]\n",
    "        \n",
    "        nexp = len(pind)\n",
    "        \n",
    "        output[sid] = np.zeros(np.append([len(np.unique(keys[:,i])) for i in range(keys.shape[1])], nexp))\n",
    "\n",
    "        for j in range(keys.shape[0]):\n",
    "            output[sid][tuple(keys[j])] = np.asarray([get_loss_paper(true_dict[sid][tind[i]], prediction_dict[sid][tuple(keys[j])][pind[i]]) for i in range(nexp)]) \n",
    "                \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homo_loocv_predictions_all = {}\n",
    "homo_loocv_predictions_wt = {}\n",
    "homo_reg_proj_vcount_norm_renorms= {}\n",
    "for sid in major_structure_ids:\n",
    "    homo_loocv_predictions_all[sid ] = msvds[sid].loocv_predictions_all\n",
    "    homo_loocv_predictions_wt[sid ] = msvds[sid].loocv_predictions_wt\n",
    "    homo_reg_proj_vcount_norm_renorms[sid ] = msvds[sid].reg_proj_vcount_norm_renorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exps = np.asarray(data_info.index.values , dtype = np.int)\n",
    "creline = {}\n",
    "for sid in major_structure_ids:\n",
    "    msvd = msvds[sid]\n",
    "    experiment_ids = np.asarray(list(msvd.experiments.keys()))\n",
    "    nexp = len(experiment_ids)\n",
    "    creline[sid] = np.zeros(nexp, dtype = object)\n",
    "    for i in range(len(experiment_ids)):\n",
    "        index = np.where(exps == experiment_ids[i])[0][0]\n",
    "        creline[sid][i] = data_info['transgenic-line'].iloc[index]\n",
    "\n",
    "#inds_bad are where there is no injection\n",
    "#we can use these to train but shouldnt to evaluate\n",
    "#the 'wt_ind' should just be 'eval_ind'\n",
    "inds_bad = {}\n",
    "inds_good = {}\n",
    "for sid in major_structure_ids:\n",
    "    injections = msvds[sid].injections \n",
    "    inds_bad[sid] = np.where(injections.sum(axis = 1) == 0.)[0]\n",
    "    inds_good[sid] = np.where(injections.sum(axis = 1) > 0.)[0]\n",
    "    \n",
    "nms = len(major_structure_ids)\n",
    "#ngam = len(gammas)\n",
    "wt_2ormore = {}\n",
    "losses_reg_norm = np.zeros((nms,ngam))\n",
    "inds_good_wt = {}\n",
    "inds_good_wtsub = {}\n",
    "for m in range(nms):\n",
    "    sid = major_structure_ids[m]\n",
    "    wt_inds = np.where(creline[sid] == 'C57BL/6J')[0]\n",
    "    wt_2ormore[sid] = np.asarray([])\n",
    "    #wt_2ormore is the indices of when there are 2 or more wild types\n",
    "    if len(wt_inds) > 1:\n",
    "        wt_2ormore[sid] = np.append(wt_2ormore[sid],wt_inds)\n",
    "    wt_2ormore[sid] = np.asarray(wt_2ormore[sid], dtype = int)\n",
    "    inds_good_wt[sid] = np.intersect1d(wt_2ormore[sid], inds_good[sid])\n",
    "    inds_good_wtsub[sid] = np.where(np.isin(wt_2ormore[sid], inds_good[sid]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "a= [list(range(5))]\n",
    "keys = np.asarray(list(itertools.product(*a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses_all = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = inds_good, true_ind = inds_good,keys = keys)\n",
    "losses_wts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_wt,pred_ind = inds_good_wtsub, true_ind = inds_good_wt, keys = keys)\n",
    "losses_allwts = get_loss(homo_reg_proj_vcount_norm_renorms, homo_loocv_predictions_all,pred_ind = inds_good_wt, true_ind = inds_good_wt, keys = keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gamma(losses, keys):\n",
    "    \n",
    "    major_structure_ids = np.asarray(list(losses.keys()))\n",
    "    nms = len(major_structure_ids)\n",
    "    nkey = keys.shape[1]\n",
    "    output = np.zeros((nms,nkey))\n",
    "    for m in range(nms):\n",
    "        print(m)\n",
    "        sid = major_structure_ids[m]\n",
    "        lvec = np.asarray([np.nanmean(losses[sid][key]) for key in keys])\n",
    "        output[m] = keys[np.nanargmin(lvec)]\n",
    "        #if len(np.where(np.isnan(np.nanmean(losses[sid][:,:], axis = 1)))[0]) < losses[sid].shape[0]:\n",
    "        #    output[m] = np.nanargmin(np.nanmean(losses[sid][:,:], axis = 1))\n",
    "    \n",
    "    output = np.asarray(output, dtype = int)\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "a= [list(range(5))]\n",
    "keys = np.asarray(list(itertools.product(*a)))\n",
    "sel_ga_all = get_gamma(losses_all,keys)\n",
    "sel_ga_allwt = sel_ga_all#get_gamma(losses_allwt,keys)\n",
    "#sel_ga_wt = get_gamma(losses_wts,keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ms_loss(losses, gammas):\n",
    "    \n",
    "    major_structure_ids = np.asarray(list(losses.keys()))\n",
    "    nms = len(major_structure_ids)\n",
    "    output = np.zeros(nms)\n",
    "    for m in range(nms):\n",
    "        sid = major_structure_ids[m]\n",
    "        output[m] = np.nanmean(losses[sid][gammas[m],:])\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonkoelle/anaconda3/envs/allen_010719_5/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mean_nw_all = get_ms_loss(losses_all, sel_ga_all)\n",
    "mean_nw_allwt = get_ms_loss(losses_allwts, sel_ga_all)\n",
    "#mean_nw_wt = get_ms_loss(losses_all, sel_ga_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90097783, 0.77737892, 0.35946378, 0.29377341, 0.43029092,\n",
       "       0.47135974, 0.40976477, 0.44626504, 0.45657043, 0.53027727,\n",
       "       0.69085557, 0.42870434])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_nw_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.20922247,        nan, 0.26124218, 0.26865134, 0.28385839,\n",
       "       0.26417285, 0.39617524, 0.2177794 , 0.57632538, 0.50071204,\n",
       "       0.48259818, 0.34852249])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_nw_allwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses2 = np.asarray(mean_nw_allwt[[4,7,2,1,10,9,11,3,5,8,6,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28385839, 0.2177794 , 0.26124218,        nan, 0.48259818,\n",
       "       0.50071204, 0.34852249, 0.26865134, 0.26417285, 0.57632538,\n",
       "       0.39617524, 1.20922247])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen_010719_5",
   "language": "python",
   "name": "allen_010719_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
